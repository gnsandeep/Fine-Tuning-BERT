{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import emoji\n",
    "from pprint import pprint\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('Tweets.csv')\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "#df = df[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterdata = pd.read_csv(\"dataPandas.csv\")\n",
    "twitterdata = twitterdata.reindex(np.random.permutation(twitterdata.index))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCounts(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def count_regex(self, pattern, tweet):\n",
    "        return len(re.findall(pattern, tweet))\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # fit method is used when specific operations need to be done on the train data, but not on the test data\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        count_words = X.apply(lambda x: self.count_regex(r'\\w+', x)) \n",
    "        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', x))\n",
    "        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', x))\n",
    "        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
    "        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?', x))\n",
    "        count_urls = X.apply(lambda x: self.count_regex(r'http.?://[^\\s]+[\\s]?', x))\n",
    "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "        # Moreover, it will result in having more words in the tweet\n",
    "        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: self.count_regex(r':[a-z_&]+:', x))\n",
    "        \n",
    "        df = pd.DataFrame({'count_words': count_words\n",
    "                           , 'count_mentions': count_mentions\n",
    "                           , 'count_hashtags': count_hashtags\n",
    "                           , 'count_capital_words': count_capital_words\n",
    "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
    "                           , 'count_urls': count_urls\n",
    "                           , 'count_emojis': count_emojis\n",
    "                          })\n",
    "        \n",
    "        return df\n",
    "    \n",
    "tc = TextCounts()\n",
    "#df_eda = tc.fit_transform(df.text)\n",
    "#df_eda['airline_sentiment'] = df.airline_sentiment\n",
    "\n",
    "#twitterdata_eda = pd.read_csv(\"dataPandas.csv\")\n",
    "twitterdata_eda = tc.fit_transform(twitterdata.Tweets)\n",
    "twitterdata_eda['Labels'] = twitterdata.Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)    \n",
    "   \n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "#sr_clean = ct.fit_transform(df.text)\n",
    "#sr_clean.sample(5)\n",
    "sr_clean_td = ct.fit_transform(twitterdata.Tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records have no words left after text cleaning\n"
     ]
    }
   ],
   "source": [
    "empty_clean = sr_clean_td == ''\n",
    "print('{} records have no words left after text cleaning'.format(sr_clean_td[empty_clean].count()))\n",
    "#sr_clean.loc[empty_clean] = '[no_text]'\n",
    "sr_clean_td.loc[empty_clean] = '[no_text]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(sr_clean)\n",
    "\n",
    "cv_ = CountVectorizer()\n",
    "bow = cv_.fit_transform(sr_clean_td)\n",
    "word_freq = dict(zip(cv.get_feature_names(), np.asarray(bow.sum(axis=0)).ravel()))\n",
    "word_counter = collections.Counter(word_freq)\n",
    "word_counter_df = pd.DataFrame(word_counter.most_common(20), columns = ['word', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['count_words', 'count_mentions', 'count_hashtags', 'count_capital_words', 'count_excl_quest_marks', 'count_urls', 'count_emojis', 'Labels', 'clean_text']\n"
     ]
    }
   ],
   "source": [
    "#df_model = df_eda\n",
    "#df_model['clean_text'] = sr_clean\n",
    "#print(df_model.columns.tolist())\n",
    "df_model_td = twitterdata_eda\n",
    "df_model_td['clean_text'] = sr_clean_td\n",
    "print(df_model_td.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols   \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment, test_size=0.1, random_state=37)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df_model_td.drop('Labels', axis=1), df_model_td.Labels, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None, is_w2v=False):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "    if is_w2v:\n",
    "        w2vcols = []\n",
    "        for i in range(SIZE):\n",
    "            w2vcols.append(i)\n",
    "        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                                 , ('w2v', ColumnExtractor(cols=w2vcols))]\n",
    "                                , n_jobs=-1)\n",
    "    else:\n",
    "        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                                 , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n",
    "                                , n_jobs=-1)    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)    # Make sure you have scikit-learn version 0.19 or higher to use multiple scoring metrics\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)    \n",
    "    t0 = time()\n",
    "    print(X_train.columns.tolist())\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()    \n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "                        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "#parameters_vect = {\n",
    "#    'features__pipe__vect__max_df':  (0.25,0.75),\n",
    "#    'features__pipe__vect__ngram_range': ((1, 2)),\n",
    "#    'features__pipe__vect__min_df': (1,2)\n",
    "#}\n",
    "\n",
    "#parameters_vect = {\n",
    "#    'features__pipe__vect__max_df': (0.25, 0.5, 0.75, 0.9),\n",
    "#    'features__pipe__vect__ngram_range': ((1, 1), (1, 2) , (2,2)),\n",
    "#    'features__pipe__vect__min_df': (1,2),\n",
    "#    'features__pipe__vect__sublinear_tf' : (True , False),\n",
    "#    'features__pipe__vect__max_features' : (None , 500 , 1000 , 5000)\n",
    "#}\n",
    "\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': ( 0.25, 0.5, 0.75, 0.9),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2) ,(2,2)),\n",
    "    'features__pipe__vect__min_df': (1,2),\n",
    "    'features__pipe__vect__sublinear_tf' : (True , False)\n",
    "}\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}\n",
    "# Parameter grid settings for LogisticRegression\n",
    "#parameters_logreg = {\n",
    "#    'clf__C': (0.25,0.5,1.0,2.0,5.0,10.0,100.0,1000.0,10000.0),\n",
    " #   'clf__C': (0.25, 0.5, 1.0),\n",
    "\n",
    "#    'clf__penalty': ('l1' , 'l2')\n",
    "    #'clf__max_iter': (100,500,1000,5000)\n",
    "#}\n",
    "parameters_logreg = {\n",
    "    'clf__C': (0.25,0.5,1.0,2.0,3.0,4.0,5.0,6.0,7.0),\n",
    "    'clf__penalty': ('l1', 'l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>synonym rude cheap realli know valu custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>flight jacksonvil fl dalla show cancel flightl go rebook anoth flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6919</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>chging flight isit possibl pay fare differ dollar ticket bought complet via point redempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>add get go work tomorrow like wait late flightr cs suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>also inappropri lie passeng induc accept voucher tell avail late flightr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "1712   18           1               2               0                     \n",
       "11975  23           1               0               0                     \n",
       "6919   22           1               0               0                     \n",
       "14030  29           1               0               1                     \n",
       "1907   25           1               0               0                     \n",
       "\n",
       "       count_excl_quest_marks  count_urls  count_emojis  \\\n",
       "1712   0                       0           0              \n",
       "11975  2                       0           0              \n",
       "6919   1                       0           0              \n",
       "14030  0                       0           0              \n",
       "1907   0                       0           0              \n",
       "\n",
       "                                                                                      clean_text  \n",
       "1712   synonym rude cheap realli know valu custom                                                 \n",
       "11975  flight jacksonvil fl dalla show cancel flightl go rebook anoth flight                      \n",
       "6919   chging flight isit possibl pay fare differ dollar ticket bought complet via point redempt  \n",
       "14030  add get go work tomorrow like wait late flightr cs suck                                    \n",
       "1907   also inappropri lie passeng induc accept voucher tell avail late flightr                   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "['count_words', 'count_mentions', 'count_hashtags', 'count_capital_words', 'count_excl_quest_marks', 'count_urls', 'count_emojis', 'clean_text']\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 30.990s\n",
      "\n",
      "Best CV score: 0.776\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.5\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.784\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.91      0.86       911\n",
      "     neutral       0.66      0.48      0.56       320\n",
      "    positive       0.77      0.72      0.74       233\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1464\n",
      "   macro avg       0.75      0.70      0.72      1464\n",
      "weighted avg       0.77      0.78      0.77      1464\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "['count_words', 'count_mentions', 'count_hashtags', 'count_capital_words', 'count_excl_quest_marks', 'count_urls', 'count_emojis', 'clean_text']\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 84.555s\n",
      "\n",
      "Best CV score: 0.795\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.811\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.93      0.88       911\n",
      "     neutral       0.73      0.53      0.62       320\n",
      "    positive       0.80      0.74      0.77       233\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1464\n",
      "   macro avg       0.79      0.73      0.75      1464\n",
      "weighted avg       0.81      0.81      0.80      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()# MultinomialNB\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "#joblib.dump(best_mnb_countvect, '../output/best_mnb_countvect.pkl')# LogisticRegression\n",
    "best_logreg_countvect = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "#joblib.dump(best_logreg_countvect, '../output/best_logreg_countvect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vect1(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None, is_w2v=False):\n",
    "    \n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    #textcountscols = ['count_emojis','count_words']\n",
    "    \n",
    "    if is_w2v:\n",
    "        w2vcols = []\n",
    "        for i in range(SIZE):\n",
    "            w2vcols.append(i)\n",
    "        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                                 , ('w2v', ColumnExtractor(cols=w2vcols))]\n",
    "                                , n_jobs=-1)\n",
    "    else:\n",
    "        features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "                                 , ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text')), ('vect', vect)]))]\n",
    "                                , n_jobs=-1)    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)    # Make sure you have scikit-learn version 0.19 or higher to use multiple scoring metrics\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)    \n",
    "    t0 = time()\n",
    "    print(X_train.columns.tolist())\n",
    "    grid_search.fit(X_train, y_train1)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()    \n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test1))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test1, grid_search.best_estimator_.predict(X_test)))\n",
    "                        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0, 2.0, 5.0, 10.0, 100.0, 1000.0, 10000.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75, 0.9),\n",
      " 'features__pipe__vect__max_features': (None, 500, 1000),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2), (2, 2)),\n",
      " 'features__pipe__vect__sublinear_tf': (True, False)}\n",
      "['count_words', 'count_mentions', 'count_hashtags', 'count_capital_words', 'count_excl_quest_marks', 'count_urls', 'count_emojis', 'clean_text', 'clean_text_wordlist']\n",
      "Fitting 5 folds for each of 2592 candidates, totalling 12960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter sublinear_tf for estimator CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=0.25, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n        tokenizer=None, vocabulary=None). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 514, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 147, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 224, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 701, in set_params\n    self._set_params('transformer_list', **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 224, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 147, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 52, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 224, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 215, in set_params\n    (key, self))\nValueError: Invalid parameter sublinear_tf for estimator CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=0.25, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n        tokenizer=None, vocabulary=None). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-4e27481dcd4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#best_mnb_countvect = grid_vect1(mnb, parameters_mnb, X_train1, X_test1, parameters_text=parameters_vect, vect=countvect)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#joblib.dump(best_mnb_countvect, '../output/best_mnb_countvect.pkl')# LogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbest_logreg_countvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_vect1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_logreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcountvect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#joblib.dump(best_logreg_countvect, '../output/best_logreg_countvect.pkl')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-d1785ec001fc>\u001b[0m in \u001b[0;36mgrid_vect1\u001b[1;34m(clf, parameters_clf, X_train, X_test, parameters_text, vect, is_w2v)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done in %0.3fs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter sublinear_tf for estimator CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=0.25, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n        tokenizer=None, vocabulary=None). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer()# MultinomialNB\n",
    "#best_mnb_countvect = grid_vect1(mnb, parameters_mnb, X_train1, X_test1, parameters_text=parameters_vect, vect=countvect)\n",
    "#joblib.dump(best_mnb_countvect, '../output/best_mnb_countvect.pkl')# LogisticRegression\n",
    "#best_logreg_countvect = grid_vect1(logreg, parameters_logreg, X_train1, X_test1, parameters_text=parameters_vect, vect=countvect)\n",
    "#joblib.dump(best_logreg_countvect, '../output/best_logreg_countvect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75, 0.9),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2), (2, 2)),\n",
      " 'features__pipe__vect__sublinear_tf': (True, False)}\n",
      "['count_words', 'count_mentions', 'count_hashtags', 'count_capital_words', 'count_excl_quest_marks', 'count_urls', 'count_emojis', 'clean_text']\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4320 out of 4320 | elapsed: 30.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1845.458s\n",
      "\n",
      "Best CV score: 0.775\n",
      "Best parameters set:\n",
      "\tclf__C: 3.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "\tfeatures__pipe__vect__sublinear_tf: True\n",
      "Test score with best_estimator_: 0.776\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " NOT_SARCASM       0.80      0.73      0.76       249\n",
      "     SARCASM       0.75      0.82      0.79       251\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       500\n",
      "   macro avg       0.78      0.78      0.78       500\n",
      "weighted avg       0.78      0.78      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfvect = TfidfVectorizer()# MultinomialNB\n",
    "#best_mnb_tfidf = grid_vect1(mnb, parameters_mnb, X_train1, X_test1, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "#joblib.dump(best_mnb_tfidf, '../output/best_mnb_tfidf.pkl')# LogisticRegression\n",
    "best_logreg_tfidf = grid_vect1(logreg, parameters_logreg, X_train1, X_test1, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "#joblib.dump(best_logreg_tfidf, '../output/best_logreg_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vote', 0.999025285243988),\n",
       " ('presid', 0.9915638566017151),\n",
       " ('elect', 0.9825637340545654)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = 50\n",
    "X_train1['clean_text_wordlist'] = X_train1.clean_text.apply(lambda x : word_tokenize(x))\n",
    "X_test1['clean_text_wordlist'] = X_test1.clean_text.apply(lambda x : word_tokenize(x))\n",
    "model = gensim.models.Word2Vec(X_train1.clean_text_wordlist\n",
    ", min_count=1\n",
    ", size=SIZE\n",
    ", window=5\n",
    ", workers=4)\n",
    "\n",
    "model.most_similar('trump', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_w2v_vector(w2v_dict, tweet):\n",
    "    list_of_word_vectors = [w2v_dict[w] for w in tweet if w in w2v_dict.vocab.keys()]\n",
    "    \n",
    "    if len(list_of_word_vectors) == 0:\n",
    "        result = [0.0]*SIZE\n",
    "    else:\n",
    "        result = np.sum(list_of_word_vectors, axis=0) / len(list_of_word_vectors)\n",
    "        \n",
    "    return result\n",
    "\n",
    "X_train1_w2v = X_train1['clean_text_wordlist'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))\n",
    "X_test1_w2v = X_test1['clean_text_wordlist'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_w2v = pd.DataFrame(X_train1_w2v.values.tolist(), index= X_train1.index)\n",
    "X_test1_w2v = pd.DataFrame(X_test1_w2v.values.tolist(), index= X_test1.index)# Concatenate with the TextCounts variables\n",
    "X_train1_w2v = pd.concat([X_train1_w2v, X_train1.drop(['clean_text', 'clean_text_wordlist'], axis=1)], axis=1)\n",
    "X_test1_w2v = pd.concat([X_test1_w2v, X_test1.drop(['clean_text', 'clean_text_wordlist'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0), 'clf__penalty': ('l1', 'l2')}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 'count_words', 'count_mentions', 'count_hashtags', 'count_capital_words', 'count_excl_quest_marks', 'count_urls', 'count_emojis']\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 9.239s\n",
      "\n",
      "Best CV score: 0.714\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "Test score with best_estimator_: 0.716\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " NOT_SARCASM       0.76      0.66      0.71       262\n",
      "     SARCASM       0.68      0.77      0.72       238\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       500\n",
      "   macro avg       0.72      0.72      0.72       500\n",
      "weighted avg       0.72      0.72      0.72       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    9.0s finished\n"
     ]
    }
   ],
   "source": [
    "best_logreg_w2v = grid_vect1(logreg, parameters_logreg, X_train1_w2v, X_test1_w2v, is_w2v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    ",'count_mentions','count_urls','count_words']\n",
    "\n",
    "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    ", ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    ", ('vect', TfidfVectorizer(max_df=0.5, min_df=1, ngram_range=(1,2) , sublinear_tf= True))]))]\n",
    ", n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([('features', features)\n",
    ", ('clf', LogisticRegression(C=3, penalty='l2'))\n",
    "])\n",
    "\n",
    "#features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    "#, ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    "#, ('vect', TfidfVectorizer(max_df=0.5, min_df=1, ngram_range=(1,2) , sublinear_tf= False))]))]\n",
    "#, n_jobs=-1)\n",
    "\n",
    "\n",
    "#pipeline = Pipeline([('features', features)\n",
    "#, ('clf', LogisticRegression(C=7, penalty='l2'))\n",
    "#])\n",
    "\n",
    "best_model = pipeline.fit(df_model_td.drop('Labels', axis=1), df_model_td.Labels)\n",
    "#(df_model_td.drop('Labels', axis=1), df_model_td.Labels, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata = pd.read_csv(\"dftestdata.csv\")\n",
    "#twittertestdata.Tweets = twittertestdata['Tweets'].apply(preprocess_tweet_text)\n",
    "\n",
    "#tf_vector_test = get_feature_vector(np.array(twittertestdata.iloc[:, 1]).ravel())\n",
    "#X_testing = tf_vector.transform(np.array(twittertestdata.iloc[:, 1]).ravel())\n",
    "\n",
    "df_counts_pos = tc.transform(twittertestdata['Tweets'])\n",
    "df_clean_pos = ct.transform(twittertestdata['Tweets'])\n",
    "df_model_pos = df_counts_pos\n",
    "df_model_pos['clean_text'] = df_clean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prediction = best_model.predict(df_model_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata['PredictLG'] = best_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata.to_csv('answerCVLG.txt', columns = [\"ID\" , \"PredictLG\"] , header = False , index = False)\n",
    "#twittertestdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    ",'count_mentions','count_urls','count_words']\n",
    "\n",
    "features = FeatureUnion([('textcounts', ColumnExtractor(cols=textcountscols))\n",
    ", ('pipe', Pipeline([('cleantext', ColumnExtractor(cols='clean_text'))\n",
    ", ('vect', CountVectorizer(max_df=0.5, min_df=1, ngram_range=(1,2)))]))]\n",
    ", n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([('features', features)\n",
    ", ('clf', MultinomialNB(alpha=0.5))\n",
    "])\n",
    "\n",
    "best_modelNB = pipeline.fit(df_model_td.drop('Labels', axis=1), df_model_td.Labels)\n",
    "#(df_model_td.drop('Labels', axis=1), df_model_td.Labels, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictionNB = best_modelNB.predict(df_model_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata['PredictNB'] = best_predictionNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittertestdata.to_csv('answerNB.txt', columns = [\"ID\" , \"PredictNB\"] , header = False , index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
